{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/feliks/Documents/faceid/venv/lib/python3.10/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:69: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from predict_face import pred_face, draw_on\n",
    "from photo_video_matching import matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@59.171] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('./data/db/feliks/0.jpg'): can't open/read file: check file path/integrity\n",
      "1it [00:00,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image ./data/db/feliks/0.jpg deleted successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 0\n",
      "1 1 0\n",
      "2 1 0\n",
      "3 1 0\n",
      "4 1 0\n",
      "5 1 0\n",
      "6 1 0\n",
      "7 1 0\n",
      "8 1 0\n",
      "9 1 0\n",
      "10 1 0\n",
      "11 1 0\n",
      "12 1 0\n",
      "13 1 0\n",
      "14 1 0\n",
      "15 1 0\n",
      "16 1 0\n",
      "17 1 0\n",
      "18 1 0\n",
      "19 1 0\n",
      "verified T 0.6738165\n"
     ]
    }
   ],
   "source": [
    "matching(\"/home/feliks/Downloads/photo_5256188845681137684_y.jpg\", \"/home/feliks/Downloads/IMG_1393.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@3.507] global loadsave.cpp:248 findDecoder imread_('insightface/data/raw/feliks/photo_5256188845681137672_y.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@3.508] global loadsave.cpp:248 findDecoder imread_('insightface/data/raw/feliks/photo_5256188845681137672_y.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minsightface/data/raw/feliks/photo_5256188845681137672_y.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpred_face\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      6\u001b[0m img, names \u001b[38;5;241m=\u001b[39m draw_on(img_path)\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(img[:,:,::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/faceid/faceid_insightface/predict_face.py:11\u001b[0m, in \u001b[0;36mpred_face\u001b[0;34m(new_image_path)\u001b[0m\n\u001b[1;32m      8\u001b[0m new_image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(new_image_path)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Use the face detection model to detect faces\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m bboxes, kpss \u001b[38;5;241m=\u001b[39m \u001b[43mdet_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdefault\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize lists to store results\u001b[39;00m\n\u001b[1;32m     14\u001b[0m detected_people \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/Documents/faceid/venv/lib/python3.10/site-packages/insightface/model_zoo/retinaface.py:211\u001b[0m, in \u001b[0;36mRetinaFace.detect\u001b[0;34m(self, img, input_size, max_num, metric)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m input_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    209\u001b[0m input_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;28;01mif\u001b[39;00m input_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m input_size\n\u001b[0;32m--> 211\u001b[0m im_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    212\u001b[0m model_ratio \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(input_size[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m input_size[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im_ratio\u001b[38;5;241m>\u001b[39mmodel_ratio:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "img_path = 'insightface/data/raw/feliks/photo_5256188845681137672_y.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "print(pred_face(img_path))\n",
    "\n",
    "img, names = draw_on(img_path)\n",
    "plt.imshow(img[:,:,::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
